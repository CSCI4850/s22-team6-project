{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2fd008c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "\n",
    "videoPath = \"imageExamples\\\\drive.mp4\"\n",
    "#videoPath = \"imageExamples\\\\drive2.mp4\"\n",
    "\n",
    "#used to detect edges in an image/frame\n",
    "def canyEdgeDetector(image):\n",
    "    edged = cv2.Canny(image, 250, 350)\n",
    "    return edged\n",
    "\n",
    "\n",
    "#create a area of interest we care about \n",
    "def getROI(image):\n",
    "    height = image.shape[0]\n",
    "    width = image.shape[1]\n",
    "    # Defining Triangular ROI: The values will change as per your camera mounts\n",
    "    triangle = np.array([[(0, height-150), (width, height-150), (int(width/(1.5)), int(height/1.6)), (int(width/(4)), int(height/1.6))]])\n",
    "    # creating black image same as that of input image\n",
    "    black_image = np.zeros_like(image)\n",
    "    # Put the Triangular shape on top of our Black image to create a mask\n",
    "    mask = cv2.fillPoly(black_image, triangle, 255)\n",
    "    # applying mask on original image\n",
    "    masked_image = cv2.bitwise_and(image, mask)\n",
    "    return masked_image\n",
    "\n",
    "#finds the lines in the image\n",
    "def getLines(image): #note: threshold of 30 seems to work well on lines\n",
    "\tlines = cv2.HoughLinesP(image, 0.3, np.pi/180, 30, np.array([]), minLineLength=50, maxLineGap=20)\n",
    "\treturn lines\n",
    "\n",
    "\n",
    "def displayLines(image, lines):\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line.reshape(4) #converting to 1d array\n",
    "            cv2.line(image, (x1, y1), (x2, y2), (255, 50, 255), 5)\n",
    "    return image\n",
    "\n",
    "# creating the videocapture object\n",
    "# and reading from the input file\n",
    "# Change it to 0 if reading from webcam\n",
    "cap = cv2.VideoCapture(videoPath)\n",
    "\n",
    "# used to record the time when we processed last frame\n",
    "prev_frame_time = 0\n",
    "\n",
    "# used to record the time at which we processed current frame\n",
    "new_frame_time = 0\n",
    "\n",
    "# Reading the video file until finished\n",
    "while(cap.isOpened()):\n",
    " \n",
    "    # Capture frame-by-frame\n",
    " \n",
    "    ret, frame = cap.read()\n",
    " \n",
    "    # if video finished or no Video Input\n",
    "    if not ret:\n",
    "        break\n",
    " \n",
    "    # Our operations on the frame come here\n",
    "    gray = frame\n",
    "\n",
    "    # resizing the frame size according to our need\n",
    "    gray = cv2.resize(gray, (900, 700))\n",
    "    canny = canyEdgeDetector(gray)\n",
    "    roi = getROI(canny)\n",
    "\n",
    "\n",
    "\n",
    "    #get the lines in roi\n",
    "    lines = getLines(roi)\n",
    "\n",
    "\n",
    "    gray = displayLines(gray,lines)\n",
    "\n",
    "\n",
    " \n",
    "    # font which we will be using to display FPS\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    # time when we finish processing for this frame\n",
    "    new_frame_time = time.time()\n",
    " \n",
    "    # Calculating the fps\n",
    " \n",
    "    # fps will be number of frame processed in given time frame\n",
    "    # since their will be most of time error of 0.001 second\n",
    "    # we will be subtracting it to get more accurate result\n",
    "    fps = 1/(new_frame_time-prev_frame_time)\n",
    "    prev_frame_time = new_frame_time\n",
    " \n",
    "    # converting the fps into integer\n",
    "    fps = int(fps)\n",
    " \n",
    "    # converting the fps to string so that we can display it on frame\n",
    "    # by using putText function\n",
    "    fps = str(fps)\n",
    " \n",
    "    # putting the FPS count on the frame\n",
    "    cv2.putText(gray, fps, (7, 70), font, 3, (100, 255, 0), 3, cv2.LINE_AA)\n",
    " \n",
    "    # displaying the frame with fps\n",
    "    cv2.imshow('frame', gray)\n",
    "\n",
    "    #DEBUG OUTPUTS\n",
    "    #cv2.imshow('frame', canny)\n",
    "    #cv2.imshow('frame', roi)\n",
    " \n",
    "    # press 'Q' if you want to exit\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    " \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "# Destroy the all windows now\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8f279d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cpu",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
